import numpy as np
import pandas as pd
import torch
from sklearn.metrics.pairwise import cosine_similarity
from transformers import AutoModel, AutoTokenizer
import re

# BERT ëª¨ë¸ ë¡œë“œ
model_name = "kykim/bert-kor-base"
tokenizer = AutoTokenizer.from_pretrained(model_name)
bert_model = AutoModel.from_pretrained(model_name)


# ì‹œ/ë„ ë‹¨ìœ„ ì§€ì—­ëª… ì¶”ì¶œ í•¨ìˆ˜
def extract_main_region(address):
    match = re.match(r'([^ ]+)', str(address))  # ì²« ë²ˆì§¸ ê³µë°± ì´ì „ì˜ ë‹¨ì–´ ì¶”ì¶œ
    return match.group(1) if match else ""

# íˆ¬ì ê·œëª¨ì— ë”°ë¥¸ ê¸°ì—… ìœ í˜• ë¶„ë¥˜
def classify_business_size(investment):
    if investment < 10:
        return 'ì†Œìƒê³µì¸'
    elif investment < 120:
        return 'ì†Œê¸°ì—…'
    elif investment < 300:
        return 'ì¤‘ê¸°ì—…'
    else:
        return 'ëŒ€ê¸°ì—…'


# ê¸°ì—… ìœ í˜•ë³„ ìµœê³  ì ìˆ˜ ì§€ì—­ ì°¾ê¸°
def get_top_industries_by_business_size(df, business_size):
    if business_size not in df.columns:
        return pd.DataFrame(columns=["ì§€ì—­ë³„", "ì‚°ì—…ë³„(10ì°¨)ëŒ€ë¶„ë¥˜", business_size])
    industry_max_scores = df.groupby("ì‚°ì—…ë³„(10ì°¨)ëŒ€ë¶„ë¥˜")[business_size].transform(max)
    top_regions = df[df[business_size] == industry_max_scores]

    return top_regions.groupby("ì‚°ì—…ë³„(10ì°¨)ëŒ€ë¶„ë¥˜").apply(lambda x: x.sample(1)).reset_index(drop=True)


# BERT ì„ë² ë”© ì¶”ì¶œ (ì‚¬ì—… ì„¤ëª…ì„ í•¨ê»˜ ë°˜ì˜)
def get_embedding(text):
    inputs = tokenizer(text, return_tensors="pt", padding=True, truncation=True, max_length=128)
    with torch.no_grad():
        outputs = bert_model(**inputs)
    # ë°°ì¹˜ ì°¨ì›ë§Œ ì œê±°í•˜ë„ë¡ squeeze(0)ë¥¼ ì‚¬ìš©í•˜ì—¬ (1, hidden_dim) -> (hidden_dim,)
    return outputs.last_hidden_state.mean(dim=1).squeeze(0).numpy()


def get_most_similar_region(region, infra_df, tokenizer, bert_model):
    """
    ê°€ì¥ ìœ ì‚¬í•œ ì§€ì—­ì„ BERT ì„ë² ë”© ìœ ì‚¬ë„ë¡œ ì°¾ëŠ” í•¨ìˆ˜

    Parameters:
        region (str): ì¡°íšŒí•  ì§€ì—­ëª…
        infra_df (pd.DataFrame): ì¸í”„ë¼ ë°ì´í„°í”„ë ˆì„
        tokenizer: BERT í† í¬ë‚˜ì´ì € ê°ì²´
        bert_model: BERT ëª¨ë¸ ê°ì²´

    Returns:
        str: ê°€ì¥ ìœ ì‚¬í•œ ì§€ì—­ëª…
    """
    region_vector = get_embedding(region).reshape(1, -1)
    best_match = None
    best_score = -1

    for candidate_region in infra_df["ì§€ì—­"].unique():
        candidate_vector = get_embedding(candidate_region).reshape(1, -1)
        score = cosine_similarity(region_vector, candidate_vector)[0][0]
        if score > best_score:
            best_match = candidate_region
            best_score = score

    return best_match if best_match else region
# BERT ê¸°ë°˜ ê±°ë¦¬ ì¶”ì²œ (ì‚°ì—…êµ° + ì‚¬ì—… ì„¤ëª… ë°˜ì˜)
def recommend_specialized_street(region, industry, business_desc, specialized_street_data):
    relevant_streets = specialized_street_data[
        specialized_street_data["ëŒ€ì§€ì—­"].astype(str).str.contains(region, na=False, case=False)]

    if relevant_streets.empty:
        return "ì¶”ì²œ ê±°ë¦¬ ì—†ìŒ"

    # ê±°ë¦¬ ì„¤ëª…ì„ BERT ì„ë² ë”© ë³€í™˜
    street_descriptions = relevant_streets["ê±°ë¦¬ì†Œê°œ"].astype(str).tolist()
    street_embeddings = np.array([get_embedding(desc) for desc in street_descriptions]).squeeze()

    # ì‚°ì—…êµ° + ì‚¬ì—… ì„¤ëª…ì„ ê²°í•©í•œ ì„ë² ë”© ìƒì„±
    combined_text = f"{industry} {business_desc}"
    industry_embedding = get_embedding(combined_text).squeeze()

    # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
    similarities = cosine_similarity([industry_embedding], street_embeddings).flatten()
    best_match_index = similarities.argmax()
    best_similarity_score = similarities[best_match_index]
    print(similarities[best_match_index])
    if best_similarity_score >= 0.2:
        return relevant_streets.iloc[best_match_index][["ê±°ë¦¬ëª…", "ì†Œì¬ì§€ë„ë¡œëª…"]].to_dict()
    return "ì¶”ì²œ ê±°ë¦¬ ì—†ìŒ"

# BERT ê¸°ë°˜ ê·œì œíŠ¹êµ¬ ìœ ì‚¬ë„ ë¶„ì„ í•¨ìˆ˜
def find_best_matching_regulatory_zone(business_desc, regulatory_df):
    business_embedding = get_embedding(business_desc)
    regulatory_df["í†µí•©ì„¤ëª…"] = (
            regulatory_df["ì‚¬ì—…ëª…"] + " " +
            regulatory_df["í˜„í–‰ ê·œì œë‚´ìš©"] + " " +
            regulatory_df["ì™„í™”ëœ ê·œì œë‚´ìš©"]
    )
    regulatory_texts = regulatory_df["í†µí•©ì„¤ëª…"].astype(str).tolist()
    regulatory_embeddings = [get_embedding(text) for text in regulatory_texts]

    similarities = cosine_similarity([business_embedding], regulatory_embeddings).flatten()
    # ìœ ì‚¬ë„ê°€ 0.2 ì´ìƒì¸ ì¸ë±ìŠ¤ ëª¨ë‘ ì„ íƒ
    indices = [idx for idx, score in enumerate(similarities) if score >= 0.2]

    if not indices:
        return None

    # ìœ ì‚¬ë„ ìˆœìœ¼ë¡œ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
    indices = sorted(indices, key=lambda i: similarities[i], reverse=True)

    results = []
    for idx in indices:
        row = regulatory_df.iloc[idx]
        results.append({
            "ì§€ì—­ëª…": row["ì§€ì—­"],
            "íŠ¹êµ¬ëª…": row["ì‚¬ì—…ëª…"],
            "í˜„í–‰ ê·œì œë‚´ìš©": row["í˜„í–‰ ê·œì œë‚´ìš©"],
            "ì™„í™”ëœ ê·œì œë‚´ìš©": row["ì™„í™”ëœ ê·œì œë‚´ìš©"],
            "ìœ ì‚¬ë„ ì ìˆ˜": round(float(similarities[idx]), 4)
        })

    return results
# BERT ê¸°ë°˜ ê·œì œíŠ¹êµ¬ ìœ ì‚¬ë„ ë¶„ì„ í•¨ìˆ˜
def find_best_matching_opportunity_zone(business_desc, opportunity_df):
    business_embedding = get_embedding(business_desc)
    print("----------")
    print(opportunity_df)
    opportunity_texts = opportunity_df["ì„¸ë¶€ì‚¬ì—…"].astype(str).tolist()
    opportunity_embeddings = [get_embedding(text) for text in opportunity_texts]

    similarities = cosine_similarity([business_embedding], opportunity_embeddings).flatten()
    best_match_index = similarities.argmax()
    best_score = similarities[best_match_index]

    if best_score >= 0.2:
        best_match = opportunity_df.iloc[best_match_index]
        return {
            "ì§€ì—­ëª…": best_match["ì§€ì—­"],
            "ê¸°íšŒë°œì „íŠ¹êµ¬ì‚¬ì—…": best_match["ì„¸ë¶€ì‚¬ì—…"],
            "ìœ ì‚¬ë„ ì ìˆ˜": round(float(best_score), 4)
        }
    return None
def find_best_matching_develop_zone(business_desc, local_develop_df):
    business_embedding = get_embedding(business_desc)
    local_develop_df["í†µí•©ì„¤ëª…"] = (
            local_develop_df["ì§€ì—­"] + " " +
            local_develop_df["íŠ¹êµ¬ëª…"] + " " +
            local_develop_df["í˜œíƒ"]
    )
    print("----------")
    print(local_develop_df)
    local_texts = local_develop_df["í†µí•©ì„¤ëª…"].astype(str).tolist()
    local_embeddings = [get_embedding(text) for text in local_texts]

    similarities = cosine_similarity([business_embedding], local_embeddings).flatten()
    best_match_index = similarities.argmax()
    best_score = similarities[best_match_index]

    if best_score >= 0.5:
        best_match = local_develop_df.iloc[best_match_index]
        print("--------------")
        print(best_match)
        return {
            "ì§€ì—­ëª…": best_match["ì§€ì—­"],
            "ì§€ì—­ê°œë°œíŠ¹êµ¬": best_match["íŠ¹êµ¬ëª…"],
            "x": best_match["ìœ„ë„"],
            "y": best_match["ê²½ë„"],
            "í˜œíƒ": best_match["í˜œíƒ"],
            "ìœ ì‚¬ë„ ì ìˆ˜": round(float(best_score), 4)
        }
    return None


def get_infra_info(region, infra_df):
    infra_info = infra_df[infra_df["ì§€ì—­"] == region]
    # ğŸ”¹ í•´ë‹¹ ì§€ì—­ì˜ ë°ì´í„° í•„í„°ë§
    if not infra_info.empty:
        return infra_info  # âœ… DataFrame ê·¸ëŒ€ë¡œ ë°˜í™˜
    else:
        return None  # ë°ì´í„°ê°€ ì—†ìœ¼ë©´ None ë°˜í™˜

def get_eco_info(region, eco_df):
    eco_info = eco_df[eco_df["ì§€ì—­"] == region]
    if not eco_info.empty:
        return eco_info
    else:
        return None
# ê¸°ì—… ë°ì´í„° ê¸°ë°˜ ì¶”ì²œ ì‹œìŠ¤í…œ
def recommend_region_for_business(business_df, industry_df,regulatory_df,opportunity_df,local_develop_df,infra_df,eco_df):
    specialized_street_data = pd.read_csv("data/specialized_street_data.csv", encoding="utf-8")
    specialized_street_data["ëŒ€ì§€ì—­"] = specialized_street_data["ì†Œì¬ì§€ë„ë¡œëª…"].apply(extract_main_region)
    print(specialized_street_data)
    recommendations = []
    for _, row in business_df.iterrows():
        specialize = row.get("íŠ¹êµ¬ì¢…ë¥˜", None)
        print(specialize)
        industry = row["ì‚°ì—…êµ°"]
        tax1= row["ë²•ì¸ì„¸"]
        tax3= row["ì¬ì‚°ì„¸"]
        land = row["ë¶€ì§€í¬ê¸°"]
        bill = row["ì„ëŒ€ë£Œ"]*10000000
        print(industry)
        business_desc = row["ì‚¬ì—… ì„¤ëª…"]
        print(business_desc)
        investment = row["íˆ¬ì ê·œëª¨ (ì–µì›)"]
        infra1 = None
        infra2 = None
        infra3 = None
        if len(row["ì¸í”„ë¼"])> 0 :
            infra1 = row["ì¸í”„ë¼"][0]
        elif len(row["ì¸í”„ë¼"])> 1:
            infra2 = row["ì¸í”„ë¼"][1]
        elif len(row["ì¸í”„ë¼"])> 2:
            infra3 = row["ì¸í”„ë¼"][2]
        business_size = classify_business_size(investment)

        if specialize == "ê·œì œììœ íŠ¹êµ¬":
            regulatory_zones = find_best_matching_regulatory_zone(business_desc, regulatory_df)
            if regulatory_zones:
                # ìœ ì‚¬ë„ ì ìˆ˜ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬ í›„ ìƒìœ„ 3ê°œ ì„ íƒ
                top_zones = sorted(regulatory_zones, key=lambda zone: zone["ìœ ì‚¬ë„ ì ìˆ˜"], reverse=True)[:3]
                candidates = []  # ê° í›„ë³´ ì •ë³´ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸
                for zone in top_zones:
                    region = zone["ì§€ì—­ëª…"]
                    infra_data = get_infra_info(region, infra_df)# í•´ë‹¹ ì§€ì—­ì˜ ì¸í”„ë¼ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
                    eco_data = get_eco_info(region,eco_df)
                    if eco_data is not None:
                        if isinstance(eco_data, pd.DataFrame):
                            eco_data = eco_data.iloc[0]
                        eco_data["í‰ë‹¹ì„ëŒ€ë£Œ"] = eco_data["í‰ë‹¹ì„ëŒ€ë£Œ"].astype(float)
                        eco_data["ë¶€ì§€í˜œíƒ"] = eco_data["ë¶€ì§€í˜œíƒ"].astype(float)
                        land = float(land)
                        sailbill = eco_data["ë¶€ì§€í˜œíƒ"]*eco_data["í‰ë‹¹ì„ëŒ€ë£Œ"]*land
                        current_bill = sailbill/ bill
                        sailtax1 = tax1*eco_data["ë²•ì¸ì„¸í˜œíƒ"]
                        sailtax3 = tax3*eco_data["ì¬ì‚°ì„¸í˜œíƒ"]
                        taxresult = tax1+tax3
                        sailtaxresult = sailtax1+sailtax3
                        ssresult = taxresult -sailtaxresult
                        percentagetax = (taxresult - sailtaxresult)/taxresult
                    if infra_data is not None:
                        # ë§Œì•½ infra_dataê°€ DataFrameì´ë©´, ì²« ë²ˆì§¸ í–‰ë§Œ ì‚¬ìš©í•˜ì—¬ Seriesë¡œ ë³€í™˜
                        if isinstance(infra_data, pd.DataFrame):
                            infra_data = infra_data.iloc[0]
                        # ì£¼ê±°ì ìˆ˜ ê³„ì‚°
                        livingscore = (
                                (infra_data["ì•„íŒŒíŠ¸ í˜„í™©"] * 0.1
                                 - infra_data["30ë…„ì´ìƒ ë…¸í›„ì£¼íƒ ë¶„í¬í˜„í™©"] * 0.01
                                 + infra_data["ì—°ë¦½ ë° ë‹¤ì„¸ëŒ€ ì£¼íƒ í˜„í™©"])
                                * infra_data["ì£¼íƒë‹¹ í‰ê·  ê°€êµ¬ì›"]
                        )
                        # êµí†µì ìˆ˜ ê³„ì‚°
                        busscore = infra_data["1ì¸ë‹¹ ìë™ì°¨ ë“±ë¡ëŒ€ìˆ˜"] * (
                                infra_data["ì „ê¸°ì°¨ì¶©ì „ì†Œ"] * 0.1 +
                                infra_data["í†µê·¼í†µí•™ ì¸êµ¬ë³€í™”"] * 0.1
                        )
                        # ë¬¸í™”ì‹œì„¤ì ìˆ˜ ê³„ì‚°
                        infrascore = (
                                infra_data["ê³µê³µë„ì„œê´€ ë¶„í¬í˜„í™©"] -
                                infra_data["ë¬¸í™”ì‹œì„¤ 1ê°œë‹¹ ì¸êµ¬ í˜„í™©"] * 0.001
                        )
                        if infra1 is not None:
                            livingscore = livingscore*2
                        if infra2 is not None:
                            busscore = busscore*2
                        if infra3 is not None:
                            infrascore = infrascore*2

                        finalscore = (livingscore + busscore + infrascore) / 10000 * zone["ìœ ì‚¬ë„ ì ìˆ˜"]
                        if zone["ì§€ì—­ëª…"] == "ë¶€ì‚°":
                            finalscore = finalscore/5
                        elif zone["ì§€ì—­ëª…"] == "ëŒ€êµ¬":
                            finalscore = finalscore/5
                        # ê³„ì‚°ëœ ì ìˆ˜ë¥¼ ìŠ¤ì¹¼ë¼(float) ê°’ìœ¼ë¡œ ë³€í™˜
                        livingscore = float(livingscore)
                        busscore = float(busscore)
                        infrascore = float(infrascore)
                        finalscore = float(finalscore)
                    else:
                        livingscore = None
                        busscore = None
                        infrascore = None
                        finalscore = None
                    sailbill = int(sailbill)
                    candidate = {
                        "ê¸°ì—…ëª…": row["ê¸°ì—…ëª…"],
                        "ì‚°ì—…êµ°": industry,
                        "ì¶”ì²œ ì§€ì—­": region,
                        "ì¶”ì²œ ê±°ë¦¬": "ê·œì œíŠ¹êµ¬ ì¶”ì²œì— ë”°ë¥¸ ê±°ë¦¬ ì¶”ì²œ ì—†ìŒ",
                        "ì¶”ì²œ ê·œì œíŠ¹êµ¬": zone,  # í›„ë³´ íŠ¹êµ¬ ì •ë³´
                        "íˆ¬ì ê·œëª¨": investment,
                        "ìœ ì‚¬ë„ ì ìˆ˜": zone["ìœ ì‚¬ë„ ì ìˆ˜"],
                        "ì£¼ê±°ì ìˆ˜": livingscore,
                        "êµí†µì ìˆ˜": busscore,
                        "ë¬¸í™”ì‹œì„¤ì ìˆ˜": infrascore,
                        "ìµœì¢…ì ìˆ˜": finalscore,
                        "ì›ë˜ì„¸ê¸ˆ": taxresult,
                        "ì ˆì•½ì„¸ê¸ˆ": sailtaxresult,
                        "ë‚´ëŠ”ì„¸ê¸ˆ" : ssresult,
                        "percentagetax": percentagetax,
                        "í˜„ì¬ë¶€ì§€ë¹„ìš©":bill,
                        "í• ì¸ë¶€ì§€ë¹„ìš©":sailbill,
                        "percentagebill":current_bill,
                    }
                    candidates.append(candidate)

                # ìµœì¢…ì ìˆ˜ê°€ Noneì´ë©´ ë§¤ìš° ë‚®ì€ ê°’(-ë¬´í•œëŒ€)ìœ¼ë¡œ ì²˜ë¦¬í•˜ì—¬ ì •ë ¬
                sorted_candidates = sorted(
                    candidates,
                    key=lambda c: c["ìµœì¢…ì ìˆ˜"] if c["ìµœì¢…ì ìˆ˜"] is not None else float('-inf'),
                    reverse=True
                )
                # ì •ë ¬ëœ ëª¨ë“  í›„ë³´ ì •ë³´ë¥¼ recommendationsì— ì¶”ê°€
                recommendations.extend(sorted_candidates)
            break
        elif specialize == "ê¸°íšë°œì „íŠ¹êµ¬":
            opportunity_zone = find_best_matching_opportunity_zone(business_desc, opportunity_df)
            if opportunity_zone:
                recommendations.append({
                    "ê¸°ì—…ëª…": row["ê¸°ì—…ëª…"],
                    "ì‚°ì—…êµ°": industry,
                    "ì¶”ì²œ ì§€ì—­": opportunity_zone["ê¸°íšŒë°œì „íŠ¹êµ¬ì‚¬ì—…"],
                    "ì¶”ì²œ ê±°ë¦¬": "ê¸°íšŒë°œì „íŠ¹êµ¬ ì¶”ì²œì— ë”°ë¥¸ ê±°ë¦¬ ì¶”ì²œ ì—†ìŒ",
                    "ì¶”ì²œ ê¸°íšŒë°œì „íŠ¹êµ¬": opportunity_zone,
                    "íˆ¬ì ê·œëª¨": investment
                })
                break
        elif specialize == "ì§€ì—­íŠ¹í™”ë°œì „íŠ¹êµ¬":
            local_develop_zone = find_best_matching_develop_zone(business_desc, local_develop_df)
            if local_develop_zone:
                recommendations.append({
                    "ê¸°ì—…ëª…": row["ê¸°ì—…ëª…"],
                    "ì‚°ì—…êµ°": industry,
                    "ì¶”ì²œ ì§€ì—­": local_develop_zone["ì§€ì—­ê°œë°œíŠ¹êµ¬"],
                    "x":local_develop_zone["x"],
                    "y":local_develop_zone["y"],
                    "í˜œíƒ":local_develop_zone["í˜œíƒ"],
                    "ìœ ì‚¬ë„ì ìˆ˜":local_develop_zone["ìœ ì‚¬ë„ ì ìˆ˜"],
                })
                break
        elif specialize == None:
            relevant_industries = get_top_industries_by_business_size(industry_df, business_size)
            print(get_top_industries_by_business_size(industry_df, business_size))
            matching_region = relevant_industries[
                relevant_industries["ì‚°ì—…ë³„(10ì°¨)ëŒ€ë¶„ë¥˜"].astype(str).str.contains(industry, na=False, case=False)]
            print(matching_region)
            if not matching_region.empty:
                recommended_region = matching_region.sample(1)["ì§€ì—­ë³„"].values[0]
            else:
                recommended_region = "ì¶”ì²œ ì§€ì—­ ì—†ìŒ"
            # ì‚°ì—…êµ° + ì‚¬ì—… ì„¤ëª…ì„ ë°˜ì˜í•œ ê±°ë¦¬ ì¶”ì²œ
            recommended_street = recommend_specialized_street(recommended_region, industry, business_desc,
                                                              specialized_street_data)

            recommendations.append({
                "ê¸°ì—…ëª…": row["ê¸°ì—…ëª…"],
                "ì‚°ì—…êµ°": industry,
                "ì¶”ì²œ ì§€ì—­": recommended_region,
                "ì¶”ì²œ ê±°ë¦¬": recommended_street,
                "íˆ¬ì ê·œëª¨": investment
            })
    print(pd.DataFrame(recommendations))
    return pd.DataFrame(recommendations)